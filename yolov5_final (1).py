# -*- coding: utf-8 -*-
"""YOLOV5_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LpiEExXgirrOK-6DppKGnfgOE7qu7r-w
"""

import os
import shutil
import yaml
import json
import subprocess
from sklearn.model_selection import train_test_split

# ==========================
# STEP 1: Setup Kaggle API
# ==========================
kaggle_api = {
    "username": "moelsaka01",  # Replace with your Kaggle username
    "key": "8a0e4f7b48783087d0872a2fa743c732"         # Replace with your Kaggle API key
}

os.makedirs('/root/.kaggle', exist_ok=True)
with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(kaggle_api, file)

subprocess.run("chmod 600 /root/.kaggle/kaggle.json", shell=True, check=True)

# ==========================

# STEP 2: Download Datasets (Fish and Coral only)
# ==========================
def download_and_extract(dataset_name, dataset_path, kaggle_url):
    os.makedirs(dataset_path, exist_ok=True)

    # Skip downloading if the dataset already exists
    if len(os.listdir(dataset_path)) > 0:
        print(f"✅ {dataset_name} dataset already exists. Skipping download.")
        return

    try:
        print(f"📥 Downloading {dataset_name} Dataset...")
        subprocess.run(f"kaggle datasets download -d {kaggle_url} -p {dataset_path} --force", shell=True, check=True)
        subprocess.run(f"unzip -o -q {dataset_path}/*.zip -d {dataset_path}", shell=True, check=True)
        print(f"✅ {dataset_name} Dataset downloaded and extracted successfully.")
    except subprocess.CalledProcessError as e:
        print(f"⚠️ Failed to download {dataset_name} Dataset: {e}")

download_and_extract("Fish", "/content/dataset/fish", "vencerlanz09/deep-fish-object-detection")
download_and_extract("Coral", "/content/dataset/coral", "jxwleong/coral-reef-dataset")

import os
import shutil
import random
from sklearn.model_selection import train_test_split

download_and_extract("Fish", "/content/dataset/fish", "vencerlanz09/deep-fish-object-detection")
download_and_extract("Coral", "/content/dataset/coral", "jxwleong/coral-reef-dataset")

# ==========================
# STEP 3: Ensure Correct Dataset Structure
# ==========================
def prepare_yolo_structure(dataset_path):
    img_dir = os.path.join(dataset_path, 'images')
    label_dir = os.path.join(dataset_path, 'labels')

    os.makedirs(img_dir, exist_ok=True)
    os.makedirs(label_dir, exist_ok=True)

    # Move images and labels into the correct folders
    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            src_file = os.path.join(root, file)
            if file.endswith(('.jpg', '.png', '.jpeg')):
                dest_file = os.path.join(img_dir, file)
            elif file.endswith('.txt'):
                dest_file = os.path.join(label_dir, file)
            else:
                continue

            # Skip moving if the file already exists
            if not os.path.exists(dest_file):
                shutil.move(src_file, dest_file)

    # Check if images exist before splitting
    images = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]

    if len(images) == 0:
        print(f"⚠️ No images found in {img_dir}. Skipping dataset preparation.")
        return  # Exit function if no images are found

    print(f"✅ Found {len(images)} images in {dataset_path}")

    # Ensure the dataset is properly split into train/val sets
    train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42) if len(images) > 1 else (images, [])

    os.makedirs(os.path.join(img_dir, 'train'), exist_ok=True)
    os.makedirs(os.path.join(img_dir, 'val'), exist_ok=True)
    os.makedirs(os.path.join(label_dir, 'train'), exist_ok=True)
    os.makedirs(os.path.join(label_dir, 'val'), exist_ok=True)

    # Move images and labels into train/val folders
    for img in train_imgs:
        src_img = os.path.join(img_dir, img)
        dest_img = os.path.join(img_dir, 'train', img)
        if not os.path.exists(dest_img):
            shutil.move(src_img, dest_img)

        label_name = img.rsplit('.', 1)[0] + '.txt'
        src_label = os.path.join(label_dir, label_name)
        dest_label = os.path.join(label_dir, 'train', label_name)
        if os.path.exists(src_label) and not os.path.exists(dest_label):
            shutil.move(src_label, dest_label)

    for img in val_imgs:
        src_img = os.path.join(img_dir, img)
        dest_img = os.path.join(img_dir, 'val', img)
        if not os.path.exists(dest_img):
            shutil.move(src_img, dest_img)

        label_name = img.rsplit('.', 1)[0] + '.txt'
        src_label = os.path.join(label_dir, label_name)
        dest_label = os.path.join(label_dir, 'val', label_name)
        if os.path.exists(src_label) and not os.path.exists(dest_label):
            shutil.move(src_label, dest_label)

    print(f"✅ Dataset prepared successfully: {len(train_imgs)} train, {len(val_imgs)} val")

# ✅ Prepare datasets (Fish and Coral only)
prepare_yolo_structure('/content/dataset/fish')
prepare_yolo_structure('/content/dataset/coral')

# ==========================
# STEP 4: Create YOLOv5 Data Config
# ==========================
data_yaml = {
    'train': '/content/dataset/fish/images/train',
    'val': '/content/dataset/fish/images/val',
    'nc': 2,  # Number of classes: Fish and Coral
    'names': ['fish', 'coral']
}

os.makedirs("/content/yolov5/data", exist_ok=True)
with open('/content/yolov5/data/data.yaml', 'w') as file:
    yaml.dump(data_yaml, file)

print("✅ data.yaml created successfully.")

import os
import subprocess
import torch

# ==========================
# 🛑 STEP 1: Remove Existing YOLOv5 Installation (if any)
# ==========================
if os.path.exists("/content/yolov5"):
    print("🗑️ Removing existing YOLOv5 directory...")
    subprocess.run("rm -rf /content/yolov5", shell=True, check=True)

# ==========================
# 📥 STEP 2: Clone YOLOv5 Repository
# ==========================
print("📥 Cloning YOLOv5 repository...")
subprocess.run("git clone https://github.com/ultralytics/yolov5.git /content/yolov5", shell=True, check=True)

# ==========================
# 📦 STEP 3: Install YOLOv5 Dependencies
# ==========================
print("📦 Installing YOLOv5 dependencies...")
requirements_path = "/content/yolov5/requirements.txt"

if os.path.exists(requirements_path):
    subprocess.run(f"pip install -r {requirements_path}", shell=True, check=True)
else:
    print("⚠️ requirements.txt not found! Installing dependencies manually...")
    subprocess.run("pip install torch torchvision torchaudio", shell=True, check=True)
    subprocess.run("pip install pyyaml matplotlib opencv-python tqdm seaborn pandas ultralytics", shell=True, check=True)

# ==========================
# ✅ STEP 4: Verify Installation
# ==========================
print("🔍 Verifying PyTorch and CUDA availability...")
print("CUDA Available:", torch.cuda.is_available())
print("PyTorch Version:", torch.__version__)

# If CUDA is not available, reinstall PyTorch with GPU support
if not torch.cuda.is_available():
    print("❌ CUDA is not available! Installing PyTorch with GPU support...")
    subprocess.run("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118", shell=True, check=True)
📥 Cloning YOLOv5 repository...

import os
import subprocess

# Check if YOLOv5 directory exists
if not os.path.exists("/content/yolov5"):
    print("📥 Cloning YOLOv5 repository...")
    subprocess.run("git clone https://github.com/ultralytics/yolov5.git /content/yolov5", shell=True, check=True)
else:
    print("✅ YOLOv5 already exists. Skipping cloning.")

# Install dependencies
print("📦 Installing YOLOv5 dependencies...")
subprocess.run("pip install -r /content/yolov5/requirements.txt", shell=True, check=True)

import os

dataset_path_fish = "/content/dataset/fish/images/train"
dataset_path_coral = "/content/dataset/coral/images/train"

# Check dataset directories
if not os.path.exists(dataset_path_fish):
    print(f"❌ Dataset missing: {dataset_path_fish}")
else:
    print(f"✅ Dataset exists: {dataset_path_fish}")

if not os.path.exists(dataset_path_coral):
    print(f"❌ Dataset missing: {dataset_path_coral}")
else:
    print(f"✅ Dataset exists: {dataset_path_coral}")

import subprocess

try:
    print("📦 Installing YOLOv5 dependencies...")
    subprocess.run("pip install -r /content/yolov5/requirements.txt", shell=True, check=True)
    print("✅ Dependencies installed successfully.")
except subprocess.CalledProcessError as e:
    print(f"❌ Dependency installation failed! Error:\n{e}")

dataset_paths = [
    "/content/dataset/fish/images/train",
    "/content/dataset/fish/images/val",
    "/content/dataset/coral/images/train",
    "/content/dataset/coral/images/val",
]

for path in dataset_paths:
    if os.path.exists(path):
        print(f"✅ Dataset exists: {path}")
    else:
        print(f"❌ Missing dataset: {path} - Re-run dataset preparation!")

yaml_path = "/content/yolov5/data/data.yaml"

if os.path.exists(yaml_path):
    print(f"✅ Found data.yaml at: {yaml_path}")
else:
    print("❌ data.yaml is missing! Creating it now...")

    data_yaml = {
        'train': '/content/dataset/fish/images/train',
        'val': '/content/dataset/fish/images/val',
        'nc': 2,  # Number of classes: Fish and Coral
        'names': ['fish', 'coral']
    }

    import yaml
    with open(yaml_path, 'w') as file:
        yaml.dump(data_yaml, file)

    print("✅ data.yaml created successfully.")

import subprocess

try:
    print("🚀 Starting YOLOv5 Training...")
    subprocess.run("python /content/yolov5/train.py --img 640 --batch 16 --epochs 50 --data /content/yolov5/data/data.yaml --weights yolov5s.pt --cache", shell=True, check=True)
    print("✅ Training completed successfully!")
except subprocess.CalledProcessError as e:
    print(f"❌ Training failed! Error:\n{e}")

import os

weights_path = "/content/yolov5/runs/train/exp/weights"

if os.path.exists(weights_path):
    print(f"✅ Weights directory found: {weights_path}")
    files = os.listdir(weights_path)
    print(f"📂 Files in weights folder: {files}")

    if "best.pt" in files:
        print("✅ `best.pt` found! You can proceed with evaluation.")
    elif "last.pt" in files:
        print("⚠️ `best.pt` is missing, but `last.pt` exists. You can use `last.pt` for evaluation.")
    else:
        print("❌ Neither `best.pt` nor `last.pt` found! Training may not have saved correctly.")
else:
    print("❌ Weights directory does not exist! Training output may have failed.")

import subprocess

try:
    print("📊 Running YOLOv5 Evaluation...")
    subprocess.run("python /content/yolov5/val.py --weights /content/yolov5/runs/train/exp/weights/best.pt --data /content/yolov5/data/data.yaml --img 640", shell=True, check=True)
    print("✅ Evaluation completed successfully!")
except subprocess.CalledProcessError as e:
    print(f"❌ Evaluation failed! Error:\n{e}")

!cat /content/yolov5/runs/train/exp/train.log

import os
import cv2
import matplotlib.pyplot as plt

# Path to YOLOv5 training results
results_path = "/content/yolov5/runs/train/exp/results.png"

if os.path.exists(results_path):
    img = cv2.imread(results_path)
    plt.figure(figsize=(12, 6))
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.title("YOLOv5 Training Results (Loss, Accuracy, Metrics)")
    plt.show()
else:
    print("❌ Training results image not found! Make sure training has completed successfully.")

import pandas as pd

log_file = "/content/yolov5/runs/train/exp/results.csv"

if os.path.exists(log_file):
    df = pd.read_csv(log_file)
    print(df.tail())  # Show the last few rows of training results
else:
    print("❌ Training log file not found! Ensure training has completed successfully.")

import shutil

backup_path = "/content/drive/MyDrive/yolov5_training_backup/results.csv"

# Copy results.csv to backup
!shutil.copy("/content/yolov5/runs/train/exp/results.csv", backup_path)

print(f"✅ Training log backed up at {backup_path}")

# =============================
# STEP 1: Upload Your Image
# =============================
from google.colab import files
import cv2
import torch
import numpy as np
import matplotlib.pyplot as plt

print("Please upload an image file:")
uploaded = files.upload()

# Retrieve the uploaded filename (assuming one file)
image_filename = list(uploaded.keys())[0]
print(f"Uploaded image: {image_filename}")

# Save the uploaded image locally (optional)
with open(image_filename, 'wb') as f:
    f.write(uploaded[image_filename])

# Read the image in its original BGR format
img_bgr = cv2.imread(image_filename)
if img_bgr is None:
    raise ValueError("Error: Unable to read the uploaded image.")

# =============================
# STEP 2: Display the Original Image (Multiple Methods)
# =============================

# Method A: Using matplotlib (convert BGR to RGB) with larger display size
original_img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(32, 24))  # Increased figure size
plt.imshow(original_img_rgb)
plt.axis('off')
plt.title("Original Image (matplotlib)", fontsize=36)
plt.show()

# Method B: Using cv2_imshow (from google.colab.patches)
from google.colab.patches import cv2_imshow
print("Original Image (cv2_imshow):")
cv2_imshow(img_bgr)

# Method C: Using IPython.display with PIL
from IPython.display import Image, display
print("Original Image (IPython.display):")
display(Image(filename=image_filename))

# =============================
# STEP 3: Load Your YOLOv5 Model
# =============================
# Make sure your YOLOv5 repository is cloned to '/content/yolov5'
# and your custom weights exist at the specified path.
model = torch.hub.load(
    '/content/yolov5',                # Path to local YOLOv5 repo
    'custom',
    path='/content/yolov5/runs/train/exp/weights/best.pt',  # Update path if needed
    source='local'
)

# =============================
# STEP 4: Run Inference (Keep Original Resolution)
# =============================
results = model(img_bgr)  # Running on the original image

# =============================
# STEP 5: Manually Draw High-Contrast Bounding Boxes
# =============================
# Convert detection results to a DataFrame for manual drawing
df = results.pandas().xyxy[0]
annotated_img_bgr = img_bgr.copy()

# Use bright yellow for bounding boxes: in BGR, yellow is (0, 255, 255)
box_color = (0, 255, 255)
box_thickness = 4  # Increase thickness for visibility
font_scale = 1.0
font_thickness = 2

for i in range(len(df)):
    x1 = int(df.iloc[i, 0])
    y1 = int(df.iloc[i, 1])
    x2 = int(df.iloc[i, 2])
    y2 = int(df.iloc[i, 3])
    conf = df.iloc[i, 4]
    class_name = df.iloc[i, 6]

    # Draw the bounding box on the image
    cv2.rectangle(annotated_img_bgr, (x1, y1), (x2, y2), box_color, thickness=box_thickness)

    # Prepare and draw the label text above the box
    label = f"{class_name} {conf:.2f}"
    cv2.putText(annotated_img_bgr, label, (x1, max(y1 - 10, 20)),
                cv2.FONT_HERSHEY_SIMPLEX, font_scale, box_color, font_thickness, cv2.LINE_AA)

# =============================
# STEP 6: Save the Annotated Image to File
# =============================
annotated_filename = "annotated_output.jpg"
cv2.imwrite(annotated_filename, annotated_img_bgr)
print(f"Annotated image saved as: {annotated_filename}")

# =============================
# STEP 7: Display the Annotated Image (Multiple Methods)
# =============================

# Convert BGR to RGB for correct display with matplotlib
annotated_img_rgb = cv2.cvtColor(annotated_img_bgr, cv2.COLOR_BGR2RGB)

# Method A: Using matplotlib with an even larger figure size
plt.figure(figsize=(32, 24))  # Increase figure size further
plt.imshow(annotated_img_rgb)
plt.axis('off')
plt.title("Annotated Image (matplotlib)", fontsize=36)
plt.show()

# Method B: Using cv2_imshow
print("Annotated Image (cv2_imshow):")
cv2_imshow(annotated_img_bgr)

# Method C: Using IPython.display with PIL
print("Annotated Image (IPython.display):")
from IPython.display import Image, display
display(Image(filename=annotated_filename))

# =============================
# STEP 8: Print Detection Details (Optional)
# =============================
print("Detected objects (bounding box data):")
print(df)

# =============================
# STEP X: Upload Video File
# =============================
from google.colab import files

print("Please upload a video file:")
uploaded_vid = files.upload()  # prompts for upload
video_filename = list(uploaded_vid.keys())[0]
print(f"Uploaded video: {video_filename}")

# =============================
# STEP X+1: Open & Prepare VideoWriter
# =============================
import cv2

cap = cv2.VideoCapture(video_filename)
if not cap.isOpened():
    raise RuntimeError(f"Failed to open video: {video_filename}")

# use same fps & frame size as input
fps    = cap.get(cv2.CAP_PROP_FPS)
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out_vid = 'annotated_output_video.mp4'
out    = cv2.VideoWriter(out_vid, fourcc, fps, (width, height))

# =============================
# STEP X+2: Process Frames
# =============================
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # run YOLOv5 inference
    results = model(frame)
    df = results.pandas().xyxy[0]

    # draw boxes & labels
    for _, row in df.iterrows():
        x1, y1 = int(row.xmin), int(row.ymin)
        x2, y2 = int(row.xmax), int(row.ymax)
        conf    = row.confidence
        cls     = row.name

        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, box_thickness)
        label = f"{cls} {conf:.2f}"
        cv2.putText(frame, label,
                    (x1, max(y1-10,20)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    font_scale, box_color,
                    font_thickness, cv2.LINE_AA)

    out.write(frame)

# =============================
# STEP X+3: Cleanup & Save
# =============================
cap.release()
out.release()
print(f"✅ Annotated video saved as: {out_vid}")